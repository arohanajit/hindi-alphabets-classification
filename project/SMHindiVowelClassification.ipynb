{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SMHindiVowelClassification.ipynb","provenance":[{"file_id":"1Rb1jnr-LcxuyUZHUpwBwMeZN73-o2wnE","timestamp":1576814247527}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SRb3CSg6nU_x","colab_type":"code","colab":{}},"source":["import os\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import torch\n","import torchvision\n","from torch.utils.data import DataLoader, Dataset, random_split\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from tqdm import tqdm_notebook\n","train_on_gpu = torch.cuda.is_available()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHqK84msKjiX","colab_type":"code","colab":{}},"source":["%%capture\n","os.environ['KAGGLE_USERNAME'\n","] = \"arohanajit232\" # username from the json file\n","os.environ['KAGGLE_KEY'\n","] = \"5289e13af33762d697c1d3c18c444f52\" # key from the json file\n","!kaggle competitions download -c padhai-hindi-vowel-consonant-classification # api copied from kaggle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eo3d93IzEVZz","colab_type":"code","colab":{}},"source":["%%capture\n","!unzip test.zip\n","!unzip train.zip\n","!mkdir dataset\n","!!mv train dataset/\n","!mv test dataset/\n","!rm train.zip\n","!rm test.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Euz2vievEXlt","colab_type":"code","colab":{}},"source":["!ls dataset/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wc67z13SAYMG","colab_type":"code","colab":{}},"source":["#For converting the dataset to torchvision dataset format\n","class VowelConsonantDataset(Dataset):\n","    def __init__(self, file_path,train=True,transform=None):\n","        self.transform = transform\n","        self.file_path=file_path\n","        self.train=train\n","        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n","        self.len = len(self.file_names)\n","        if self.train:\n","            self.classes_mapping=self.get_classes()\n","    def __len__(self):\n","        return len(self.file_names)\n","    \n","    def __getitem__(self, index):\n","        file_name=self.file_names[index]\n","        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n","        if self.transform:\n","            image_data = self.transform(image_data)\n","        if self.train:\n","            file_name_splitted=file_name.split(\"_\")\n","            Y1 = self.classes_mapping[file_name_splitted[0]]\n","            Y2 = self.classes_mapping[file_name_splitted[1]]\n","            z1,z2=torch.zeros(10),torch.zeros(10)\n","            z1[Y1-10],z2[Y2]=1,1\n","            label=torch.stack([z1,z2])\n","\n","            return image_data, label\n","\n","        else:\n","            return image_data, file_name\n","          \n","    def pil_loader(self,path):\n","        with open(path, 'rb') as f:\n","            img = Image.open(f)\n","            return img.convert('RGB')\n","\n","      \n","    def get_classes(self):\n","        classes=[]\n","        for name in self.file_names:\n","            name_splitted=name.split(\"_\")\n","            classes.extend([name_splitted[0],name_splitted[1]])\n","        classes=list(set(classes))\n","        classes_mapping={}\n","        for i,cl in enumerate(sorted(classes)):\n","            classes_mapping[cl]=i\n","        return classes_mapping"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o4OoFNIBrOIY","colab_type":"code","colab":{}},"source":["transform1 = transforms.Compose([transforms.RandomRotation(30),\n","                                       transforms.RandomResizedCrop(224),\n","                                       transforms.RandomHorizontalFlip(),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.485, 0.456, 0.406], \n","                                                            [0.229, 0.224, 0.225])])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8gCzRhMnmmIM","colab_type":"code","colab":{}},"source":["full_data=VowelConsonantDataset(\"../content/dataset/train\",train=True,transform=transform1)\n","train_size = int(0.9 * len(full_data))\n","test_size = len(full_data) - train_size\n","\n","train_data, validation_data = random_split(full_data, [train_size, test_size])\n","\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=64, shuffle=True)\n","test_data=VowelConsonantDataset(\"../content/dataset/test\",train=False)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=64,shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ucqr7l7dPEqv","colab_type":"code","colab":{}},"source":["print(len(train_data))\n","print(len(validation_data))\n","print(len(full_data))\n","full_data.get_classes()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9_zSIbSmpcn","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0wV9Wqf61OeB","colab_type":"code","colab":{}},"source":["data_iter = iter(train_loader)\n","images, labels = next(data_iter)\n","print(images[0].shape,images[0].size(0))\n","fig = plt.figure(figsize=(25, 4))\n","for idx in np.arange(20):\n","    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n","    img = np.transpose(np.squeeze(images[idx]))\n","    ax.imshow(img)\n","print(\"\\n\\n\\n\",torch.max(labels[:,0,:],1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-gIv4kB1m-OC","colab_type":"code","colab":{}},"source":["model = torchvision.models.resnet50(pretrained=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CaEHaeHu53fu","colab_type":"code","colab":{}},"source":["for param in model.parameters():\n","    param.requires_grad = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"diOwA6oS6Fc7","colab_type":"code","colab":{}},"source":["model.fc = nn.Sequential(\n","    nn.Linear(2048,1024,bias=True),\n","    nn.ReLU(True),\n","    nn.Dropout(p=0.2),\n","    nn.Linear(1024,512,bias=True),\n","    nn.ReLU(True),\n","    nn.Dropout(p=0.2),\n","    nn.Linear(512,64,bias=True),\n","    nn.ReLU(True),\n","    nn.Linear(64,10,bias=True)\n","    \n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ken0wfLYXmef","colab_type":"code","colab":{}},"source":["model.to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","opt = optim.Adam(model.parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MuotocZa3ek6","colab_type":"code","colab":{}},"source":["try:\n","    epochs = 45\n","    total_trainloss = []\n","    total_valloss = []\n","    total_trainacc = []\n","    total_valacc = []\n","    for i in tqdm_notebook(range(epochs)):\n","        train_loss = 0\n","        valid_loss = 0\n","        totalval_train = 0\n","        totalval_val = 0\n","        acc_train = 0\n","        acc_valid = 0\n","        model.train()\n","        for image,label in tqdm_notebook(train_loader):\n","            image, label = image.to(device), label.to(device)\n","            totalval_train+=64\n","            opt.zero_grad()\n","            out = model(image)\n","            val,ind = torch.max(label[:,0,:],1)\n","            _,pred_train = torch.max(out,1)\n","            acc_train += (pred_train==ind).sum().item()\n","            loss = loss_fn(out,ind)\n","            train_loss += loss.item()*image.size(0)\n","            loss.backward()\n","            opt.step()\n","            del image, label\n","        \n","        model.eval()\n","        for image,label in tqdm_notebook(validation_loader):\n","            totalval_val += 64\n","            image, label = image.to(device), label.to(device)\n","            V_out = model(image)\n","            V_val,V_ind = torch.max(label[:,0,:],1)\n","            vloss = loss_fn(V_out,V_ind)\n","            valid_loss += vloss.item()*image.size(0)\n","            _,pred_valid = torch.max(V_out,1)\n","            acc_valid += (pred_valid==V_ind).sum().item()\n","        \n","        train_loss /= len(train_loader)\n","        valid_loss /= len(validation_loader)\n","        acc_train = acc_train/totalval_train * 100\n","        acc_valid = acc_valid/totalval_val * 100\n","        total_trainloss.append(train_loss)\n","        total_valloss.append(valid_loss)\n","        total_trainacc.append(acc_train)\n","        total_valacc.append(acc_valid)\n","\n","        print('Epoch: {} Train loss: {:.2f} Validation loss: {:.2f}'.format(i,train_loss,valid_loss))\n","        print('Epoch: {} Train accuracy: {:.2f} Validation accuracy: {:.2f}'.format(i,acc_train,acc_valid))\n","        \n","    torch.save(model.state_dict(), \"best_model.pth\")\n","    del out\n","    torch.cuda.empty_cache()\n","finally:\n","    fig,(ax1,ax2) = plt.subplots(1,2,figsize=(20,5))\n","    ax1.plot(total_trainloss)\n","    ax1.plot(total_valloss)\n","    ax1.legend(['Train Loss','Validation Loss'])\n","    ax1.set_title('Loss')\n","    ax2.plot(total_trainacc)\n","    ax2.plot(total_valacc)\n","    ax2.legend(['Train accuracy','Validation Accuracy'])\n","    ax2.set_title('Accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"asi-OI8K5OBH","colab_type":"code","colab":{}},"source":["model.load_state_dict(torch.load(\"best_model.pth\"))\n","model.to(device)\n","model.eval()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mruo8zsZMT3T","colab_type":"code","colab":{}},"source":["total=0\n","v=0\n","c=0\n","for data in tqdm_notebook(validation_loader,total=len(validation_loader),unit='batch'):\n","    images,labels = data\n","    images,labels = images.to(device),labels.to(device)\n","    _,out_v = torch.max(vowel_model(images),1)\n","    _,out_c = torch.max(cons_model(images),1)\n","    _,lab1 = torch.max(labels[:,0,:],1)\n","    _,lab2 = torch.max(labels[:,1,:],1)\n","    total += 64\n","    v += (out_v==lab1).sum().item()\n","    c += (out_c==lab2).sum().item()\n","print('total images:',total)\n","print('correct vowels predictions:',v)\n","print('correct consonants predictions:',c)\n","print('Vowel Accuracy: ',(v/total)*100, '%')\n","print('Consonants Accuracy: ',(c/total)*100,'%')\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aN8sPrq4MEPh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}